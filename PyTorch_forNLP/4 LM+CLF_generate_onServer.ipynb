{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (10) : invalid device ordinal at ..\\torch\\csrc\\cuda\\Module.cpp:33",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b7736ac654b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mMAX_VOCAB_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (10) : invalid device ordinal at ..\\torch\\csrc\\cuda\\Module.cpp:33"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "# freeze random seed\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(1)\n",
    "    torch.cuda.set_device(2)\n",
    "\n",
    "MAX_VOCAB_SIZE = 100000\n",
    "EMBEDDING_SIZE = 500\n",
    "HIDDEN_SIZE = 1000\n",
    "BATCH_SIZE = 100\n",
    "BPTT_LEN = 30 #seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.torchtext for Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取Field 以及训练LM的数据集格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = torchtext.data.Field(lower=True) #变小写\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "                   path=\"./dataset\", text_field=text,\n",
    "                   train=\"corpus_havestp.txt\", \n",
    "                   validation=\"corpus_havestp.txt\", \n",
    "                   test=\"corpus_havestp.txt\" )\n",
    "\n",
    "text.build_vocab(train, max_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词数： 100002\n",
      "['<unk>', '<pad>', '，', '的', '。', '、', '了', '在', '“', '”']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('词数：',len(text.vocab))\n",
    "print(text.vocab.itos[:10] )#同C++ 11\n",
    "\n",
    "# 好习惯，及时assert\n",
    "# assert text.vocab.itos[:1] == ['<unk>', '<pad>']\n",
    "text.vocab.stoi['<unk>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=BATCH_SIZE, device=-1, \n",
    "    bptt_len=BPTT_LEN, repeat=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.iterator.BPTTIterator object at 0x7f3da5683898>\n",
      "<generator object BPTTIterator.__iter__ at 0x7f3da568be60>\n",
      "\n",
      "[torchtext.data.batch.Batch of size 100]\n",
      "\t[.text]:[torch.LongTensor of size 30x100]\n",
      "\t[.target]:[torch.LongTensor of size 30x100]\n"
     ]
    }
   ],
   "source": [
    "print(train_iter)\n",
    "print(iter(train_iter)) #迭代器，泛型指针\n",
    "it = iter(train_iter)\n",
    "print(next(it)) #返回iter的下一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 100]) torch.Size([30, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1637,     2,    10,     0,   863,  2204,   236,  2867,    12, 11144,\n",
       "         2496,    38,     2,   881,   213,  1465,     3, 16749,    45,  1025,\n",
       "         8172,  1929,   204, 54621,     3,   813,     2,  1037, 28421,    62])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "print(batch.text.shape, batch.target.shape) # seq_len * batch_size，我们更习惯反过来\n",
    "batch.text[:,0] # 因为第一个维度是“句”长，so一列是 一句话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有说法的！今天一<unk>全军2017年1月2日实名举报上黄镇宣国才的贴子（仍被锁定禁止评论）已经\n",
      "说法的！今天一<unk>全军2017年1月2日实名举报上黄镇宣国才的贴子（仍被锁定禁止评论）已经正好 \n",
      "\n",
      "正好一整年了=750)window.open('http://img.jsly001.com/attachment/mon_1801/4_\n",
      "一整年了=750)window.open('http://img.jsly001.com/attachment/mon_1801/4_291085 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    batch = next(it)\n",
    "    print(''.join([text.vocab.itos[j] for j in batch.text[:,0]]))\n",
    "    print(''.join([text.vocab.itos[j] for j in batch.target[:,0]]),'\\n')\n",
    "    # 所以虽是不同的batch，LSTM的 hidden可以一直传下去。每次截断计算图 只保留value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义模型\n",
    "|process|shape|备注|\n",
    "|:----|:----|:----|\n",
    "|TEXT|s\\*b|其实有个word_idx在里面\n",
    "|embedding|v->e|\n",
    "|after embed|s\\*e\\*b|\n",
    "|lstm|\n",
    "|after lstm |  |\n",
    "<img src='./dataset/LSTM_structure_analyse.png' align='center' width='400'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN_LM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(RNN_LM, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, text, hidden):\n",
    "        # text: seq_len * batch_size\n",
    "        emb = self.embed(text) # seq_len * embed_size * batch_size\n",
    "        lstm_out, hidden = self.lstm(emb, hidden) # y, 末尾hidden\n",
    "        # lstm_out: seq_len * batch_size * hidden_size\n",
    "        # hidden: 1 * batch_size * hidden_size, 1 * batch_size * hidden_size\n",
    "        \n",
    "        vocab_out = self.linear(lstm_out.view(-1, lstm_out.shape[2])) \n",
    "        #(seq_len * batch_size) * hidden_size 把前2维拼成1维，因为Linear只接受2维input\n",
    "        vocab_out = vocab_out.view(lstm_out.size(0),lstm_out.size(1), self.vocab_size) \n",
    "        #恢复shape:seq_len * batch_size * vocab_size\n",
    "        return vocab_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, requires_grad=True):\n",
    "        weight = next(self.parameters())\n",
    "        initrange = 2.0/(self.embed_size+self.hidden_size)\n",
    "        cell_w = weight.new_zeros(1, batch_size, self.hidden_size, requires_grad=requires_grad)\n",
    "        hidden_w = weight.new_zeros(1, batch_size, self.hidden_size, requires_grad=requires_grad)\n",
    "        with torch.no_grad():#否则无法 _operate\n",
    "            return (cell_w.uniform_(-initrange, initrange), hidden_w.uniform_(-initrange, initrange))\n",
    "        #返回：两个和weight一样的rand tensor----cell & hidden\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_LM(\n",
       "  (embed): Embedding(100002, 500)\n",
       "  (lstm): LSTM(500, 1000)\n",
       "  (linear): Linear(in_features=1000, out_features=100002, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN_LM(vocab_size=len(text.vocab),\n",
    "               embed_size=EMBEDDING_SIZE,\n",
    "               hidden_size=HIDDEN_SIZE)\n",
    "USE_CUDA = 1 #52 vs 232 per 100iters\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.5256, -0.7502, -0.6540,  ...,  0.2168, -0.1428,  1.4274],\n",
       "        [ 0.1643, -0.3161,  0.1285,  ..., -0.1286, -0.0571, -0.0711],\n",
       "        [ 1.1658,  0.1701,  0.5288,  ...,  0.4481,  0.1001,  1.5422],\n",
       "        ...,\n",
       "        [ 0.6190,  0.5853,  1.6793,  ..., -0.2505,  0.7391,  1.3023],\n",
       "        [-2.7605, -0.2259, -0.7199,  ...,  0.3644,  0.2963,  0.1062],\n",
       "        [ 0.4066,  0.4807,  0.7690,  ..., -0.4090,  1.0787, -0.7293]],\n",
       "       device='cuda:2', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()) #都在cuda上了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach() #计算图在此截断，否则相当于非常长的一样计算图\n",
    "    else:\n",
    "        return tuple(repackage_hidden(x) for x in h)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 9e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先定义评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    it = iter(data)\n",
    "    total_count = 0.\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(BATCH_SIZE, requires_grad=False)\n",
    "        for i, batch in enumerate(it):\n",
    "            data, target = batch.text, batch.target\n",
    "            if USE_CUDA:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = loss_fn(output.view(-1, len(text.vocab)), target.view(-1))\n",
    "            total_count += np.multiply(*data.size())\n",
    "            total_loss += loss.item()*np.multiply(*data.size())\n",
    "            \n",
    "    loss = total_loss / total_count\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "a = t.ones(5,6)\n",
    "a.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0  loss:11.5128 perplexity:99985.28\n",
      "0iter 耗时:4.41s\n",
      "iter: 100  loss:7.6488 perplexity:2098.15\n",
      "iter: 200  loss:7.2306 perplexity:1381.08\n",
      "iter: 300  loss:6.8902 perplexity:982.64\n",
      "iter: 500  loss:6.6771 perplexity:794.01\n",
      "iter: 600  loss:6.5617 perplexity:707.49\n",
      "iter: 800  loss:6.5260 perplexity:682.67\n",
      "iter: 1000  loss:6.2520 perplexity:519.07\n",
      "1000iter 耗时:1246.38s\n",
      "iter: 1200  loss:6.1209 perplexity:455.29\n",
      "iter: 1300  loss:6.1075 perplexity:449.23\n",
      "iter: 1400  loss:6.0799 perplexity:436.97\n",
      "iter: 1500  loss:5.8064 perplexity:332.42\n",
      "iter: 1600  loss:5.6130 perplexity:273.98\n",
      "2000iter 耗时:1260.63s\n",
      "iter: 2200  loss:5.5258 perplexity:251.09\n",
      "iter: 3000  loss:5.5202 perplexity:249.67\n",
      "3000iter 耗时:1254.76s\n",
      "iter: 3200  loss:5.4930 perplexity:242.99\n",
      "epoch: 0  loss:5.4485 perplexity:232.40\n",
      "0iter 耗时:527.14s\n",
      "iter: 100  loss:5.4673 perplexity:236.81\n",
      "iter: 200  loss:5.1618 perplexity:174.47\n",
      "iter: 500  loss:5.0713 perplexity:159.38\n",
      "iter: 600  loss:4.9923 perplexity:147.27\n",
      "iter: 1000  loss:4.9052 perplexity:134.99\n",
      "1000iter 耗时:1261.53s\n",
      "iter: 1100  loss:4.9048 perplexity:134.94\n",
      "iter: 1200  loss:4.7425 perplexity:114.72\n",
      "iter: 1500  loss:4.5536 perplexity:94.97\n",
      "iter: 1600  loss:4.5039 perplexity:90.36\n",
      "iter: 1700  loss:4.4929 perplexity:89.38\n",
      "2000iter 耗时:1262.42s\n",
      "3000iter 耗时:1251.88s\n",
      "epoch: 1  loss:4.0732 perplexity:58.75\n",
      "0iter 耗时:524.80s\n",
      "iter: 200  loss:4.3378 perplexity:76.54\n",
      "iter: 600  loss:4.2558 perplexity:70.52\n",
      "iter: 1000  loss:4.2529 perplexity:70.31\n",
      "1000iter 耗时:1257.36s\n",
      "iter: 1100  loss:4.2153 perplexity:67.71\n",
      "iter: 1200  loss:4.0801 perplexity:59.15\n",
      "iter: 1400  loss:4.0347 perplexity:56.52\n",
      "iter: 1500  loss:3.9066 perplexity:49.73\n",
      "iter: 1600  loss:3.9024 perplexity:49.52\n",
      "iter: 1700  loss:3.8701 perplexity:47.95\n",
      "2000iter 耗时:1263.59s\n",
      "3000iter 耗时:1251.04s\n",
      "epoch: 2  loss:3.1428 perplexity:23.17\n",
      "0iter 耗时:524.55s\n",
      "iter: 200  loss:3.8620 perplexity:47.56\n",
      "iter: 600  loss:3.7831 perplexity:43.95\n",
      "1000iter 耗时:1254.28s\n",
      "iter: 1200  loss:3.6624 perplexity:38.95\n",
      "iter: 1400  loss:3.5621 perplexity:35.24\n",
      "iter: 1500  loss:3.5313 perplexity:34.17\n",
      "iter: 1600  loss:3.5295 perplexity:34.11\n",
      "iter: 1700  loss:3.4712 perplexity:32.17\n",
      "2000iter 耗时:1261.09s\n",
      "3000iter 耗时:1249.48s\n",
      "epoch: 3  loss:2.5975 perplexity:13.43\n",
      "0iter 耗时:524.30s\n",
      "iter: 600  loss:3.4441 perplexity:31.31\n",
      "1000iter 耗时:1251.46s\n",
      "iter: 1200  loss:3.3480 perplexity:28.45\n",
      "iter: 1400  loss:3.2584 perplexity:26.01\n",
      "iter: 1500  loss:3.2436 perplexity:25.63\n",
      "iter: 1700  loss:3.1927 perplexity:24.35\n",
      "2000iter 耗时:1256.71s\n",
      "3000iter 耗时:1248.41s\n",
      "epoch: 4  loss:2.2558 perplexity:9.54\n",
      "0iter 耗时:523.93s\n",
      "1000iter 耗时:1249.10s\n",
      "iter: 1200  loss:3.1359 perplexity:23.01\n",
      "iter: 1400  loss:3.0213 perplexity:20.52\n",
      "iter: 1700  loss:2.9778 perplexity:19.64\n",
      "2000iter 耗时:1254.43s\n",
      "3000iter 耗时:1247.78s\n",
      "epoch: 5  loss:2.0075 perplexity:7.45\n",
      "0iter 耗时:523.14s\n",
      "1000iter 耗时:1248.25s\n",
      "iter: 1400  loss:2.8676 perplexity:17.59\n",
      "iter: 1700  loss:2.8312 perplexity:16.97\n",
      "2000iter 耗时:1251.25s\n",
      "3000iter 耗时:1248.47s\n",
      "epoch: 6  loss:1.8723 perplexity:6.50\n",
      "0iter 耗时:523.05s\n",
      "1000iter 耗时:1246.38s\n",
      "iter: 1400  loss:2.7343 perplexity:15.40\n",
      "iter: 1700  loss:2.7020 perplexity:14.91\n",
      "2000iter 耗时:1251.66s\n",
      "3000iter 耗时:1247.56s\n",
      "epoch: 7  loss:1.7287 perplexity:5.63\n",
      "0iter 耗时:523.20s\n",
      "1000iter 耗时:1248.15s\n",
      "iter: 1400  loss:2.6183 perplexity:13.71\n",
      "2000iter 耗时:1249.52s\n",
      "3000iter 耗时:1248.02s\n",
      "epoch: 8  loss:1.6494 perplexity:5.20\n",
      "0iter 耗时:523.30s\n",
      "1000iter 耗时:1248.01s\n",
      "iter: 1400  loss:2.5338 perplexity:12.60\n",
      "iter: 1700  loss:2.5272 perplexity:12.52\n",
      "2000iter 耗时:1252.29s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a1385ca3b446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#target: batch_size *1 即可\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRAD_CLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "GRAD_CLIP = 5.0\n",
    "min_loss = float(\"inf\")\n",
    "a = time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()#训练和测试不一样的，但是为啥之前都没写？\n",
    "    it = iter(train_iter)\n",
    "    hidden = model.init_hidden(BATCH_SIZE) #两个\n",
    "#     print(hidden[0].shape)\n",
    "    for i, batch in enumerate(it):\n",
    "        \n",
    "            \n",
    "        data, target = batch.text, batch.target # 都是[s,b]\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        hidden = repackage_hidden(hidden) #构建新的hidden起点\n",
    "        output, hidden = model(data, hidden) #[s,b,v], [1,b,h]\n",
    "        \n",
    "        loss = loss_fn(output.view(-1,len(text.vocab)), target.view(-1)) \n",
    "        #output: [s*b,v] \n",
    "        #target: [s*b] 即可，值就是v的index\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP) #clip grad\n",
    "        optim.step()     \n",
    "        \n",
    "        if i%100 ==0:\n",
    "            if loss.item()<min_loss:\n",
    "                print(\"iter:\", i, ' loss:%.4f'%loss.item(), 'perplexity:%.2f'%np.exp(loss.item()))\n",
    "                torch.save(model.state_dict(), './models/LSTM_s%d_e%d_h%d_b%d_p.pth'%(BPTT_LEN,EMBEDDING_SIZE,HIDDEN_SIZE,BATCH_SIZE))\n",
    "                min_loss = loss.item()\n",
    "        if i%1000 == 0:\n",
    "            print('%siter 耗时:%.2fs'%(i, time()-a))\n",
    "            a = time()\n",
    "            \n",
    "    print(\"epoch:\", epoch, ' loss:%.4f'%loss.item(), 'perplexity:%.2f'%np.exp(loss.item()))\n",
    "    \n",
    "#         if i>=4000:\n",
    "#             break\n",
    "#         if i%2 == 0:\n",
    "#             val_loss = evaluate(model, val_iter)\n",
    "#             if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "#                 print(\"better model, val loss: \", val_loss)\n",
    "#                 torch.save(model.state_dict(), \"LSTM%s.pth\"%i)\n",
    "#             else:\n",
    "#                 scheduler.step()\n",
    "#                 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#             val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = RNN_LM(len(text.vocab), EMBEDDING_SIZE, HIDDEN_SIZE)\n",
    "if USE_CUDA:\n",
    "    best_model = best_model.cuda()\n",
    "best_model.load_state_dict(torch.load('./models/LSTM_s30_e500_h1000_b100_p12e5.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "百度次要他称业务范围涵盖稳小吃中，有人在使用这一五大影响之前，已经提前30天了，在动车低1分下，预计3年内已经出现2700天才能顶店面，当块碰到了新房1就重新退房过，这还要4个月的回归到了想必大家的认可！1、重庆站：为确保安全第一款找非现行《2015年国家外国人城镇国际社会经济体系发展情况。对此，建瓯市公安局须主张通报，对近期公布的各类污染源排摸等情况进行分析，通过相关的分析研究制定具体工作方案，让有关办案人员一起交流学习的动态，优先回答，仍需取得“快乐成绩”。截至10月底，他有3个开发区\\n相关内容有新华社；6）深入挖掘的核心价值。\\n目前，26<unk>火箭创石墨垃圾，山海关德国<unk>近<unk>万；将客户利用产品等，以要准入...一条条给予最正的信任——企业向你的消费者表示自己对，“原来的专家--山东网”首页还要<unk>站在手里么？"
     ]
    }
   ],
   "source": [
    "hidden = best_model.init_hidden(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# input = torch.randint(len(text.vocab), (1, 1), dtype=torch.long).to(device)\n",
    "first_word = '百度'\n",
    "input = torch.LongTensor([[text.vocab.stoi[first_word]]]).to(device)\n",
    "num_sente = 5\n",
    "eos = {'?':1,'？':1,'.':1,'。':1,'!':1,'！':1,'<eos>':1}\n",
    "\n",
    "for i in range(1000000):\n",
    "    word = text.vocab.itos[input.item()]\n",
    "    print(word, end='')\n",
    "    \n",
    "    output, hidden = best_model(input, hidden)\n",
    "    word_prob = output.squeeze().exp().cpu() #shape:[vocab_size]\n",
    "    word_idx = torch.multinomial(word_prob, 1).item() #多项式分布采样得到一个\n",
    "#     word_idx = torch.max(word_prob, 0)[1] #max(a,0)会返回(value,index)\n",
    "    input.fill_(word_idx)\n",
    "\n",
    "    if word in eos:\n",
    "        num_sente -= 1\n",
    "        if num_sente <= 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
